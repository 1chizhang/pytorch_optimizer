## Change Log

### Feature

* Implement PAdam optimizer (#186)
  * [Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks](https://arxiv.org/abs/1806.06763) 
* Implement LOMO optimizer (#188)
  * [Full Parameter Fine-tuning for Large Language Models with Limited Resources](https://arxiv.org/abs/2306.09782) 
* Implement loss functions (#189)
  * BCELoss
  * BCEFocalLoss
  * FocalLoss
  * DiceLoss
  * LDAMLoss

### Diff

[2.10.1...2.11.0](https://github.com/kozistr/pytorch_optimizer/compare/v2.10.1...v2.11.0)
